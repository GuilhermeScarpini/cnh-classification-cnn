{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GrKhDflWNdB",
        "outputId": "9ddf7ada-e387-41a0-d7fa-44dce1bdf613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sucesso! GPU encontrada em: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models,optimizers\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU não encontrada! Verifique as configurações.')\n",
        "else:\n",
        "  print(f'Sucesso! GPU encontrada em: {device_name}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "!unzip -qo \"/content/drive/My Drive/projeto_cnh/dataset.zip\" -d \"/content/dataset_local\"\n",
        "pasta_dir = '/content/dataset_local/dataset'\n",
        "\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    pasta_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(254, 254),\n",
        "    batch_size=32\n",
        ")\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    pasta_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(254, 254),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(254, 254, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "\n",
        "modelo = models.Sequential([\n",
        "\n",
        "    layers.Rescaling(1./255, input_shape=(254, 254, 3)),\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.3),\n",
        "    layers.RandomZoom(0.3),\n",
        "    layers.RandomContrast(0.2),\n",
        "\n",
        "    base_model,\n",
        "\n",
        "\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "modelo.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "treino = modelo.fit(train_ds, epochs=15, validation_data=val_ds)\n",
        "\n",
        "\n",
        "modelo.save('/content/drive/My Drive/projeto_cnh/modelo_cnh_final.keras')\n",
        "print(\"Modelo treinado!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj6FhFoxWdC_",
        "outputId": "d2ef0627-b082-4c34-c6fb-20571bc14138"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 19900 files belonging to 2 classes.\n",
            "Using 15920 files for training.\n",
            "Found 19900 files belonging to 2 classes.\n",
            "Using 3980 files for validation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2329627467.py:24: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = tf.keras.applications.MobileNetV2(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 93ms/step - accuracy: 0.9371 - loss: 0.1402 - val_accuracy: 0.9922 - val_loss: 0.0263\n",
            "Epoch 2/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 95ms/step - accuracy: 0.9880 - loss: 0.0337 - val_accuracy: 0.9970 - val_loss: 0.0060\n",
            "Epoch 3/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 90ms/step - accuracy: 0.9900 - loss: 0.0263 - val_accuracy: 0.9997 - val_loss: 0.0026\n",
            "Epoch 4/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 90ms/step - accuracy: 0.9934 - loss: 0.0204 - val_accuracy: 0.9990 - val_loss: 0.0029\n",
            "Epoch 5/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 95ms/step - accuracy: 0.9945 - loss: 0.0150 - val_accuracy: 0.9982 - val_loss: 0.0065\n",
            "Epoch 6/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 95ms/step - accuracy: 0.9938 - loss: 0.0161 - val_accuracy: 0.9990 - val_loss: 0.0033\n",
            "Epoch 7/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 95ms/step - accuracy: 0.9962 - loss: 0.0105 - val_accuracy: 0.9975 - val_loss: 0.0057\n",
            "Epoch 8/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 91ms/step - accuracy: 0.9966 - loss: 0.0105 - val_accuracy: 0.9990 - val_loss: 0.0031\n",
            "Epoch 9/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 90ms/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.9990 - val_loss: 0.0033\n",
            "Epoch 10/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 90ms/step - accuracy: 0.9958 - loss: 0.0118 - val_accuracy: 0.9990 - val_loss: 0.0027\n",
            "Epoch 11/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 90ms/step - accuracy: 0.9971 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 12/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 89ms/step - accuracy: 0.9970 - loss: 0.0099 - val_accuracy: 0.9972 - val_loss: 0.0047\n",
            "Epoch 13/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 90ms/step - accuracy: 0.9974 - loss: 0.0094 - val_accuracy: 0.9995 - val_loss: 0.0018\n",
            "Epoch 14/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 89ms/step - accuracy: 0.9981 - loss: 0.0065 - val_accuracy: 0.9997 - val_loss: 0.0011\n",
            "Epoch 15/15\n",
            "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 94ms/step - accuracy: 0.9968 - loss: 0.0084 - val_accuracy: 0.9887 - val_loss: 0.0345\n",
            "Modelo treinado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKxT4b3tivKU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}